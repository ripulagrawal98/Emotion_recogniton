{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentor is library used for data augmentation and artificial generation of image data for our emotion detection tasks.\n",
    "\n",
    "import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset i.e. csv file from fer2013 challenge\n",
    "face = pd.read_csv('fer2013/Face Expressions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of total faces: 35887\n"
     ]
    }
   ],
   "source": [
    "print(\"No of total faces:\", face.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 0\n",
    "test = 0\n",
    "other = 0\n",
    "for i in range(len(face)):\n",
    "    if face['Usage'][i] == 'Training':\n",
    "        train += 1\n",
    "    elif face['Usage'][i] == 'PrivateTest':\n",
    "        test += 1\n",
    "    else :\n",
    "        other += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training samples: 28709\n",
      "No of public test samples: 3589\n",
      "No of private test samples: 3589\n"
     ]
    }
   ],
   "source": [
    "print('No of training samples:' ,train)\n",
    "print('No of public test samples:', other)\n",
    "print('No of private test samples:', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    8989\n",
       "6    6198\n",
       "4    6077\n",
       "2    5121\n",
       "0    4953\n",
       "5    4002\n",
       "1     547\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 = Happy\n",
    "1 = Sad\n",
    "2 = Surprise\n",
    "3 = Angry\n",
    "4 = Disgust\n",
    "5 = Fear\n",
    "6 = Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe which contain only rows which have label =1\n",
    "\n",
    "disgust = face[face['label'] == 1]\n",
    "angry = face[face['label'] == 0]\n",
    "fear = face[face['label'] == 2]\n",
    "happy = face[face['label'] == 3]\n",
    "sad = face[face['label'] == 4]\n",
    "surprise = face[face['label'] == 5]\n",
    "neutral = face[face['label'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    547\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disgust['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the Usage columns in face dataframe\n",
    "new_face = face.copy()\n",
    "new_face = new_face.drop('Usage',axis = 1)\n",
    "print(new_face.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(face.label.unique() ) \n",
    "face.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Let's start by visualizing the distribution of emotions in the dataset. \n",
    "# 0- neutral\n",
    "# 1- angry\n",
    "# 2- disgust\n",
    "# 3- fear\n",
    "# 4- happy\n",
    "# 5- sad\n",
    "# 6- surprise\n",
    "\n",
    "fig, ax = plt.subplots()  \n",
    "x = face.label.unique()  \n",
    "y = face.label.value_counts()  \n",
    "# Plotting the bar graph  \n",
    "ax.bar(x, y)  \n",
    "plt.xlabel('emotions')\n",
    "plt.ylabel('count')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract the pixels values from column of pixels from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract the pixels values from column of pixels from dataset\n",
    "pixels = face['pixels'].tolist() # 1\n",
    "width, height = 48, 48\n",
    "faces = []\n",
    "for pixel_sequence in pixels:\n",
    "    face_ = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n",
    "    face_ = np.asarray(face_).reshape(width, height) # 3\n",
    "    faces.append(face_.astype('float64'))\n",
    "\n",
    "faces = np.asarray(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the dataset according to different classes i.e. 7 emotion classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  angry faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for angry\n",
    "\n",
    "# extract the pixels values from column of pixels from dataset\n",
    "pixels = angry['pixels'].tolist() # 1\n",
    "width, height = 48, 48\n",
    "faces_angry = []\n",
    "for pixel_sequence in pixels:\n",
    "    face_ = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n",
    "    face_ = np.asarray(face_).reshape(width, height) # 3\n",
    "    \n",
    "    # There is an issue for normalizing images. Just comment out 4 and 5 lines until when I found the solution.\n",
    "    # face = face / 255.0 # 4\n",
    "    # face = cv2.resize(face.astype('uint8'), (width, height)) # 5\n",
    "    faces_angry.append(face_.astype('float64'))\n",
    "\n",
    "faces_angry = np.asarray(faces_angry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of angry faces: 4953\n"
     ]
    }
   ],
   "source": [
    "print('No of angry faces:', faces_angry.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(faces_angry)):\n",
    "    image.imsave('split_dataset/angry_faces/'+str(i)+'.png', faces_angry[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation for Angry Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 4953 image(s) found.\n",
      "Output directory set to split_dataset/angry_faces/output."
     ]
    }
   ],
   "source": [
    "path_to_data = 'split_dataset/angry_faces/'\n",
    "\n",
    "# instantiate a Pipeline object that points to a directory on our file system\n",
    "\n",
    "p = Augmentor.Pipeline(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'split_dataset/output/'\n",
    "# p = Augmentor.Pipeline(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert images to black and white\n",
    "# p.black_and_white(1,128)  \n",
    "\n",
    "# #Flip (mirror) the image along either its horizontal or vertical axis\n",
    "p.flip_random(1)\n",
    "\n",
    "# # #Performs a random, elastic gaussian distortion on an image.\n",
    "p.gaussian_distortion(probability = 0.8, grid_width = 2, grid_height = 10, magnitude = 5, corner = 'bell',\n",
    "                    method = 'out', mex=0.5, mey=0.5, sdx=0.05, sdy=0.05)\n",
    "\n",
    "# # # #Convert images to greyscale\n",
    "# # p.greyscale(probability = 1)\n",
    "\n",
    "# #Random change brightness of an image\n",
    "p.random_brightness(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change image contrast\n",
    "# p.random_contrast(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change saturation of an image\n",
    "# p.random_color(probability = 1, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Rotate an image by an arbitrary amount\n",
    "p.rotate(probability = 1, max_left_rotation = 25, max_right_rotation = 25)\n",
    "\n",
    "# #Shear the image by a specified number of degrees\n",
    "p.shear(probability = 0.9, max_shear_left = 24, max_shear_right = 23)\n",
    "\n",
    "# #Skew an image in a random direction, either left to right, top to bottom, or one of 8 corner directions.\n",
    "# p.skew(probability = 1, magnitude=1)\n",
    "\n",
    "# #Zooms into an image at a random location within the image\n",
    "# p.zoom_random(probability = 0.8, percentage_area = 0.5, randomise_percentage_area=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4953"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faces_angry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=48x48 at 0x1BE90A0BB70>: 100%|█| 4953/4953 [05:33<00:00, 14.86 Samples/s] \n"
     ]
    }
   ],
   "source": [
    "# p.sample(100)\n",
    "# augmented_images, labels = \n",
    "p.sample(4953)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disgust Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for disgust\n",
    "\n",
    "# extract the pixels values from column of pixels from dataset that have label = 1\n",
    "pixels_d = disgust['pixels'].tolist() # 1\n",
    "width, height = 48, 48\n",
    "faces_d = []\n",
    "for pixel_sequence in pixels_d:\n",
    "    face_d = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n",
    "    face_d = np.asarray(face_d).reshape(width, height) # 3\n",
    "    \n",
    "    # There is an issue for normalizing images. Just comment out 4 and 5 lines until when I found the solution.\n",
    "    # face = face / 255.0 # 4\n",
    "    # face = cv2.resize(face.astype('uint8'), (width, height)) # 5\n",
    "    faces_d.append(face_d.astype('float32'))\n",
    "\n",
    "faces_d = np.asarray(faces_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation for disgust faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save disgust faces from csv file as images into new folder\n",
    "\n",
    "for i in range(len(faces_d)):\n",
    "    image.imsave('split_dataset/disgust_faces/'+str(i)+'.png', faces_d[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 547 image(s) found.\n",
      "Output directory set to split_dataset/disgust_faces/output."
     ]
    }
   ],
   "source": [
    "path_to_disgust = 'split_dataset/disgust_faces/'\n",
    "\n",
    "# instantiate a Pipeline object that points to a directory on our file system\n",
    "\n",
    "d = Augmentor.Pipeline(path_to_disgust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert images to black and white\n",
    "# p.black_and_white(1,128)  \n",
    "\n",
    "# #Flip (mirror) the image along either its horizontal or vertical axis\n",
    "d.flip_random(1)\n",
    "\n",
    "# # #Performs a random, elastic gaussian distortion on an image.\n",
    "d.gaussian_distortion(probability = 0.8, grid_width = 2, grid_height = 10, magnitude = 5, corner = 'bell',\n",
    "                    method = 'out', mex=0.5, mey=0.5, sdx=0.05, sdy=0.05)\n",
    "\n",
    "# # # #Convert images to greyscale\n",
    "# # p.greyscale(probability = 1)\n",
    "\n",
    "# #Random change brightness of an image\n",
    "d.random_brightness(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change image contrast\n",
    "# p.random_contrast(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change saturation of an image\n",
    "# p.random_color(probability = 1, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Rotate an image by an arbitrary amount\n",
    "d.rotate(probability = 1, max_left_rotation = 25, max_right_rotation = 25)\n",
    "\n",
    "# #Shear the image by a specified number of degrees\n",
    "d.shear(probability = 0.9, max_shear_left = 24, max_shear_right = 23)\n",
    "\n",
    "# #Skew an image in a random direction, either left to right, top to bottom, or one of 8 corner directions.\n",
    "# p.skew(probability = 1, magnitude=1)\n",
    "\n",
    "# #Zooms into an image at a random location within the image\n",
    "# p.zoom_random(probability = 0.8, percentage_area = 0.5, randomise_percentage_area=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547, 48, 48)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=48x48 at 0x1BE7E9E6438>: 100%|█| 7000/7000 [06:04<00:00, 19.19 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "# p.sample(100)\n",
    "# augmented_images, labels = \n",
    "d.sample(7000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fear_path = 'split_dataset/fear_faces'\n",
    "happy_path = 'split_dataset/happy_faces'\n",
    "sur_path = 'split_dataset/surprise_faces'\n",
    "sad_path = 'split_dataset/sad_faces'\n",
    "neutral_path = 'split_dataset/neutral_faces'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(fear_path):\n",
    "    os.makedirs(fear_path)\n",
    "    \n",
    "if not os.path.exists(happy_path):\n",
    "    os.makedirs(happy_path)\n",
    "    \n",
    "if not os.path.exists(sur_path):\n",
    "    os.makedirs(sur_path)\n",
    "    \n",
    "if not os.path.exists(sad_path):\n",
    "    os.makedirs(sad_path)\n",
    "    \n",
    "if not os.path.exists(neutral_path):\n",
    "    os.makedirs(neutral_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fear Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fear\n",
    "\n",
    "# extract the pixels values from column of pixels from dataset\n",
    "pixels = fear['pixels'].tolist() # 1\n",
    "width, height = 48, 48\n",
    "faces_fear = []\n",
    "for pixel_sequence in pixels:\n",
    "    face_ = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n",
    "    face_ = np.asarray(face_).reshape(width, height) # 3\n",
    "    \n",
    "    # There is an issue for normalizing images. Just comment out 4 and 5 lines until when I found the solution.\n",
    "    # face = face / 255.0 # 4\n",
    "    # face = cv2.resize(face.astype('uint8'), (width, height)) # 5\n",
    "    faces_fear.append(face_.astype('float64'))\n",
    "\n",
    "faces_fear = np.asarray(faces_fear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of fear faces: 5121\n"
     ]
    }
   ],
   "source": [
    "print('no of fear faces:', faces_fear.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all rows as images label with fear in our dataset\n",
    "\n",
    "for i in range(len(faces_fear)):\n",
    "    image.imsave('split_dataset/fear_faces/'+str(i)+'.png', faces_fear[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation for fear faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 5121 image(s) found.\n",
      "Output directory set to split_dataset/fear_faces/output."
     ]
    }
   ],
   "source": [
    "path_to_fear = 'split_dataset/fear_faces/'\n",
    "\n",
    "# instantiate a Pipeline object that points to a directory on our file system\n",
    "\n",
    "f = Augmentor.Pipeline(path_to_fear)\n",
    "\n",
    "# #Convert images to black and white\n",
    "# p.black_and_white(1,128)  \n",
    "\n",
    "# #Flip (mirror) the image along either its horizontal or vertical axis\n",
    "f.flip_random(1)\n",
    "\n",
    "# # #Performs a random, elastic gaussian distortion on an image.\n",
    "f.gaussian_distortion(probability = 0.8, grid_width = 2, grid_height = 10, magnitude = 5, corner = 'bell',\n",
    "                    method = 'out', mex=0.5, mey=0.5, sdx=0.05, sdy=0.05)\n",
    "\n",
    "# # # #Convert images to greyscale\n",
    "# # p.greyscale(probability = 1)\n",
    "\n",
    "# #Random change brightness of an image\n",
    "f.random_brightness(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change image contrast\n",
    "# p.random_contrast(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change saturation of an image\n",
    "# p.random_color(probability = 1, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Rotate an image by an arbitrary amount\n",
    "f.rotate(probability = 1, max_left_rotation = 25, max_right_rotation = 25)\n",
    "\n",
    "# #Shear the image by a specified number of degrees\n",
    "f.shear(probability = 0.9, max_shear_left = 24, max_shear_right = 23)\n",
    "\n",
    "# #Skew an image in a random direction, either left to right, top to bottom, or one of 8 corner directions.\n",
    "# p.skew(probability = 1, magnitude=1)\n",
    "\n",
    "# #Zooms into an image at a random location within the image\n",
    "# p.zoom_random(probability = 0.8, percentage_area = 0.5, randomise_percentage_area=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=48x48 at 0x1BE90A11128>: 100%|█| 5121/5121 [04:17<00:00, 19.89 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "f.sample(5121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5121"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faces_fear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no need of augmentation for happy faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for happy\n",
    "\n",
    "# extract the pixels values from column of pixels from dataset\n",
    "pixels = happy['pixels'].tolist() # 1\n",
    "width, height = 48, 48\n",
    "faces_happy = []\n",
    "for pixel_sequence in pixels:\n",
    "    face_ = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n",
    "    face_ = np.asarray(face_).reshape(width, height) # 3\n",
    "    \n",
    "    # There is an issue for normalizing images. Just comment out 4 and 5 lines until when I found the solution.\n",
    "    # face = face / 255.0 # 4\n",
    "    # face = cv2.resize(face.astype('uint8'), (width, height)) # 5\n",
    "    faces_happy.append(face_.astype('float64'))\n",
    "\n",
    "faces_happy = np.asarray(faces_happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fear faces from csv file as images into new folder\n",
    "\n",
    "for i in range(len(faces_happy)):\n",
    "#     np.save('split_dataset/angry_faces/'+str(i)+'.png', faces_angry[i])\n",
    "    image.imsave('split_dataset/happy_faces/'+str(i)+'.png', faces_happy[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation for Happy faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 8989 image(s) found.\n",
      "Output directory set to split_dataset/happy_faces/output."
     ]
    }
   ],
   "source": [
    "path_to_happy = 'split_dataset/happy_faces/'\n",
    "\n",
    "# instantiate a Pipeline object that points to a directory on our file system\n",
    "\n",
    "h = Augmentor.Pipeline(path_to_happy)\n",
    "\n",
    "# #Convert images to black and white\n",
    "# p.black_and_white(1,128)  \n",
    "\n",
    "# #Flip (mirror) the image along either its horizontal or vertical axis\n",
    "h.flip_random(1)\n",
    "\n",
    "# # #Performs a random, elastic gaussian distortion on an image.\n",
    "h.gaussian_distortion(probability = 0.8, grid_width = 2, grid_height = 10, magnitude = 5, corner = 'bell',\n",
    "                    method = 'out', mex=0.5, mey=0.5, sdx=0.05, sdy=0.05)\n",
    "\n",
    "# # # #Convert images to greyscale\n",
    "# # p.greyscale(probability = 1)\n",
    "\n",
    "# #Random change brightness of an image\n",
    "h.random_brightness(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change image contrast\n",
    "# p.random_contrast(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change saturation of an image\n",
    "# p.random_color(probability = 1, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Rotate an image by an arbitrary amount\n",
    "h.rotate(probability = 1, max_left_rotation = 25, max_right_rotation = 25)\n",
    "\n",
    "# #Shear the image by a specified number of degrees\n",
    "h.shear(probability = 0.9, max_shear_left = 24, max_shear_right = 23)\n",
    "\n",
    "# #Skew an image in a random direction, either left to right, top to bottom, or one of 8 corner directions.\n",
    "# p.skew(probability = 1, magnitude=1)\n",
    "\n",
    "# #Zooms into an image at a random location within the image\n",
    "# p.zoom_random(probability = 0.8, percentage_area = 0.5, randomise_percentage_area=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=48x48 at 0x1BE390B6A20>: 100%|█| 8989/8989 [09:53<00:00, 15.14 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "h.sample(len(faces_happy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for surprise\n",
    "# extract the pixels values from column of pixels from dataset\n",
    "pixels = surprise['pixels'].tolist() # 1\n",
    "width, height = 48, 48\n",
    "faces_sur = []\n",
    "for pixel_sequence in pixels:\n",
    "    face_ = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n",
    "    face_ = np.asarray(face_).reshape(width, height) # 3\n",
    "    \n",
    "    # There is an issue for normalizing images. Just comment out 4 and 5 lines until when I found the solution.\n",
    "    # face = face / 255.0 # 4\n",
    "    # face = cv2.resize(face.astype('uint8'), (width, height)) # 5\n",
    "    faces_sur.append(face_.astype('float64'))\n",
    "\n",
    "faces_sur = np.asarray(faces_sur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augmentation for surprise faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 4002 image(s) found.\n",
      "Output directory set to split_dataset/surprise_faces/output."
     ]
    }
   ],
   "source": [
    "# save fear faces from csv file as images into new folder\n",
    "\n",
    "for i in range(len(faces_sur)):\n",
    "#     np.save('split_dataset/angry_faces/'+str(i)+'.png', faces_angry[i])\n",
    "    image.imsave('split_dataset/surprise_faces/'+str(i)+'.png', faces_sur[i])\n",
    "\n",
    "    \n",
    "\n",
    "path_to_sur = 'split_dataset/surprise_faces/'\n",
    "\n",
    "# instantiate a Pipeline object that points to a directory on our file system\n",
    "\n",
    "sur = Augmentor.Pipeline(path_to_sur)\n",
    "\n",
    "# #Convert images to black and white\n",
    "# p.black_and_white(1,128)  \n",
    "\n",
    "# #Flip (mirror) the image along either its horizontal or vertical axis\n",
    "sur.flip_random(1)\n",
    "\n",
    "# # #Performs a random, elastic gaussian distortion on an image.\n",
    "sur.gaussian_distortion(probability = 0.8, grid_width = 2, grid_height = 10, magnitude = 5, corner = 'bell',\n",
    "                    method = 'out', mex=0.5, mey=0.5, sdx=0.05, sdy=0.05)\n",
    "\n",
    "# # # #Convert images to greyscale\n",
    "# # p.greyscale(probability = 1)\n",
    "\n",
    "# #Random change brightness of an image\n",
    "sur.random_brightness(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change image contrast\n",
    "# p.random_contrast(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change saturation of an image\n",
    "# p.random_color(probability = 1, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Rotate an image by an arbitrary amount\n",
    "sur.rotate(probability = 1, max_left_rotation = 25, max_right_rotation = 25)\n",
    "\n",
    "# #Shear the image by a specified number of degrees\n",
    "sur.shear(probability = 0.9, max_shear_left = 24, max_shear_right = 23)\n",
    "\n",
    "# #Skew an image in a random direction, either left to right, top to bottom, or one of 8 corner directions.\n",
    "# p.skew(probability = 1, magnitude=1)\n",
    "\n",
    "# #Zooms into an image at a random location within the image\n",
    "# p.zoom_random(probability = 0.8, percentage_area = 0.5, randomise_percentage_area=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=48x48 at 0x1BE391046D8>: 100%|█| 4002/4002 [05:03<00:00, 13.17 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sur.sample(len(faces_sur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sad Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no augmentation for sad faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sad\n",
    "\n",
    "# extract the pixels values from column of pixels from dataset\n",
    "pixels = sad['pixels'].tolist() # 1\n",
    "width, height = 48, 48\n",
    "faces_sad = []\n",
    "for pixel_sequence in pixels:\n",
    "    face_ = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n",
    "    face_ = np.asarray(face_).reshape(width, height) # 3\n",
    "    \n",
    "    # There is an issue for normalizing images. Just comment out 4 and 5 lines until when I found the solution.\n",
    "    # face = face / 255.0 # 4\n",
    "    # face = cv2.resize(face.astype('uint8'), (width, height)) # 5\n",
    "    faces_sad.append(face_.astype('float64'))\n",
    "\n",
    "faces_sad = np.asarray(faces_sad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augmentation for sad faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 6077 image(s) found.\n",
      "Output directory set to split_dataset/sad_faces/output."
     ]
    }
   ],
   "source": [
    "# save fear faces from csv file as images into new folder\n",
    "\n",
    "for i in range(len(faces_sad)):\n",
    "#     np.save('split_dataset/angry_faces/'+str(i)+'.png', faces_angry[i])\n",
    "    image.imsave('split_dataset/sad_faces/'+str(i)+'.png', faces_sad[i])\n",
    "\n",
    "    \n",
    "\n",
    "path_to_sad = 'split_dataset/sad_faces/'\n",
    "\n",
    "# instantiate a Pipeline object that points to a directory on our file system\n",
    "\n",
    "s = Augmentor.Pipeline(path_to_sad)\n",
    "\n",
    "# #Convert images to black and white\n",
    "# p.black_and_white(1,128)  \n",
    "\n",
    "# #Flip (mirror) the image along either its horizontal or vertical axis\n",
    "s.flip_random(1)\n",
    "\n",
    "# # #Performs a random, elastic gaussian distortion on an image.\n",
    "s.gaussian_distortion(probability = 0.8, grid_width = 2, grid_height = 10, magnitude = 5, corner = 'bell',\n",
    "                    method = 'out', mex=0.5, mey=0.5, sdx=0.05, sdy=0.05)\n",
    "\n",
    "# # # #Convert images to greyscale\n",
    "# # p.greyscale(probability = 1)\n",
    "\n",
    "# #Random change brightness of an image\n",
    "s.random_brightness(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change image contrast\n",
    "# p.random_contrast(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change saturation of an image\n",
    "# p.random_color(probability = 1, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Rotate an image by an arbitrary amount\n",
    "s.rotate(probability = 1, max_left_rotation = 25, max_right_rotation = 25)\n",
    "\n",
    "# #Shear the image by a specified number of degrees\n",
    "s.shear(probability = 0.9, max_shear_left = 24, max_shear_right = 23)\n",
    "\n",
    "# #Skew an image in a random direction, either left to right, top to bottom, or one of 8 corner directions.\n",
    "# p.skew(probability = 1, magnitude=1)\n",
    "\n",
    "# #Zooms into an image at a random location within the image\n",
    "# p.zoom_random(probability = 0.8, percentage_area = 0.5, randomise_percentage_area=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=48x48 at 0x1BE845510F0>: 100%|█| 2000/2000 [02:37<00:00, 12.72 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s.sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutral Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for neutral\n",
    "\n",
    "# extract the pixels values from column of pixels from dataset\n",
    "pixels = neutral['pixels'].tolist() # 1\n",
    "width, height = 48, 48\n",
    "faces_neutral = []\n",
    "for pixel_sequence in pixels:\n",
    "    face_ = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n",
    "    face_ = np.asarray(face_).reshape(width, height) # 3\n",
    "    \n",
    "    # There is an issue for normalizing images. Just comment out 4 and 5 lines until when I found the solution.\n",
    "    # face = face / 255.0 # 4\n",
    "    # face = cv2.resize(face.astype('uint8'), (width, height)) # 5\n",
    "    faces_neutral.append(face_.astype('float64'))\n",
    "\n",
    "faces_neutral = np.asarray(faces_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no augmentation for neutral faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation for neutral faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 6198 image(s) found.\n",
      "Output directory set to split_dataset/neutral_faces/output."
     ]
    }
   ],
   "source": [
    "# save fear faces from csv file as images into new folder\n",
    "\n",
    "for i in range(len(faces_neutral)):\n",
    "#     np.save('split_dataset/angry_faces/'+str(i)+'.png', faces_angry[i])\n",
    "    image.imsave('split_dataset/neutral_faces/'+str(i)+'.png', faces_neutral[i])\n",
    "\n",
    "    \n",
    "\n",
    "path_to_neutral = 'split_dataset/neutral_faces/'\n",
    "\n",
    "# instantiate a Pipeline object that points to a directory on our file system\n",
    "\n",
    "n = Augmentor.Pipeline(path_to_neutral)\n",
    "\n",
    "# #Convert images to black and white\n",
    "# p.black_and_white(1,128)  \n",
    "\n",
    "# #Flip (mirror) the image along either its horizontal or vertical axis\n",
    "n.flip_random(1)\n",
    "\n",
    "# # #Performs a random, elastic gaussian distortion on an image.\n",
    "n.gaussian_distortion(probability = 0.8, grid_width = 2, grid_height = 10, magnitude = 5, corner = 'bell',\n",
    "                    method = 'out', mex=0.5, mey=0.5, sdx=0.05, sdy=0.05)\n",
    "\n",
    "# # # #Convert images to greyscale\n",
    "# # p.greyscale(probability = 1)\n",
    "\n",
    "# #Random change brightness of an image\n",
    "n.random_brightness(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change image contrast\n",
    "# p.random_contrast(probability = 0.7, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Random change saturation of an image\n",
    "# p.random_color(probability = 1, min_factor = 0.8, max_factor = 1.6)\n",
    "\n",
    "# #Rotate an image by an arbitrary amount\n",
    "n.rotate(probability = 1, max_left_rotation = 25, max_right_rotation = 25)\n",
    "\n",
    "# #Shear the image by a specified number of degrees\n",
    "n.shear(probability = 0.9, max_shear_left = 24, max_shear_right = 23)\n",
    "\n",
    "# #Skew an image in a random direction, either left to right, top to bottom, or one of 8 corner directions.\n",
    "# p.skew(probability = 1, magnitude=1)\n",
    "\n",
    "# #Zooms into an image at a random location within the image\n",
    "# p.zoom_random(probability = 0.8, percentage_area = 0.5, randomise_percentage_area=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=48x48 at 0x1BE850820B8>: 100%|█| 2000/2000 [02:29<00:00, 13.33 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Expanding the dimension of channel for each image\n",
    "# faces = np.expand_dims(faces, -1) # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels to catergorical matrix\n",
    "emotions = pd.get_dummies(face['label']) # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Converting the labels to catergorical matrix for all the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_d = disgust['label']\n",
    "label_a = angry['label']\n",
    "label_f = fear['label']\n",
    "label_h = happy['label']\n",
    "label_s = sad['label']\n",
    "label_sp = surprise['label']\n",
    "label_n = neutral['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all label as numpy array into hardisk\n",
    "\n",
    "np.save('split_dataset/angry_label.npy', label_a)\n",
    "np.save('split_dataset/disgust_label.npy',label_d)\n",
    "np.save('split_dataset/happy_label.npy',label_h)\n",
    "np.save('split_dataset/fear_label.npy',label_f)\n",
    "np.save('split_dataset/sad_label.npy',label_s)\n",
    "np.save('split_dataset/surprise_label.npy',label_sp)\n",
    "np.save('split_dataset/neutral_label.npy',label_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
